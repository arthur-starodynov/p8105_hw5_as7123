---
title: "Hw 5"
author: "Arthur Starodynov"
date: "2023-11-02"
output: html_document
---

```{r}
library(tidyverse)
library(dplyr)

```

Below we can see us reading in the data set and then from there adding a new column that takes the city and state of the where the homicide occurs and combines them. 

Another table shown below is the number of cases that are still open or have no arrest and the amount that were closed without an arrest.


```{r}
homicide_df <- read_csv("homicide-data.csv")

homicide_df <-
  homicide_df %>%
  mutate(city_state = str_c(city, ", ",state)) 

unsolved_case <- 
  homicide_df %>%
  group_by(city_state) %>%
  filter(disposition %in% c("Closed without arrest", "Open/No arrest")) %>%
  summarize(unsolved = n())

Total_case <-
  homicide_df %>%
  group_by(city_state) %>%
  summarize(total = n())


all_cases <- left_join(unsolved_case, Total_case, by = "city_state")
```


By looking at the Raw data we can see that there is a around a total of 52,000 obserations all seperated within different variable types. Some of the bigger ones to note are the city and state where the homicides occured and hwether they were closed or not by the police.


```{r, echo = FALSE}
view(homicide_df)
```


For the city of Baltimore, MD, use the prop.test function to estimate the proportion of homicides that are unsolved; save the output of prop.test as an R object, apply the broom::tidy to this object and pull the estimated proportion and confidence intervals from the resulting tidy dataframe.


```{r}
simulation  <- function(df) {
  
  simulation_i <- prop.test(df$unsolved, df$total)
  
  broom::tidy(simulation_i) %>% 
    select(estimate, conf.low, conf.high)
}
```


```{r}
all_cases %>% 
  filter(city_state == "Baltimore, MD") %>% 
  simulation() %>% 
  mutate(estimate = round(estimate, 3), 
         conf.low = round(conf.low, 3), 
         conf.high = round(conf.high, 3)) %>% 
  rename(Estimate = estimate, 
         "Lower bound" = conf.low, 
         "Upper bound" = conf.high) %>% 
  knitr::kable()

```      


Now run prop.test for each of the cities in your dataset, and extract both the proportion of unsolved homicides and the confidence interval for each. Do this within a “tidy” pipeline, making use of purrr::map, purrr::map2, list columns and unnest as necessary to create a tidy dataframe with estimated proportions and CIs for each city.

```{r, warning=FALSE, message = FALSE}
city_nest <- nest(all_cases, unsolved:total)
unsolved_ci <- city_nest %>% 
  mutate(simulation = map(data, simulation)) %>% 
  unnest() %>% 
  rename(conf_low = conf.low, 
         conf_high = conf.high)
```


Create a plot that shows the estimates and CIs for each city – check out geom_errorbar for a way to add error bars based on the upper and lower limits. Organize cities according to the proportion of unsolved homicides.


```{r}
library(ggplot2)
unsolved_ci %>%
  mutate(city_state = fct_reorder(city_state, estimate)) %>% 
  ggplot(aes(x = estimate, y = city_state)) + 
  geom_point(color = "blue") + 
  geom_errorbar(aes(xmin = conf_low, xmax = conf_high)) + 
  labs(title = "Proportion of unsolved cases in 50 major US cities", 
       y = "Proportion of unsolved cases", 
       x = "City", 
       caption = "Error bars represent 95% confidence interval") + 
  theme_classic() 
  


```




Problem 2: 


```{r, message= FALSE, warning = FASLE}
file_names <- list.files("./data/", full.names = TRUE)

full_df <- file_names %>% 
  map(read_csv) 

for (i in 1:20) {
  if (i < 11) {
    full_df[[i]] <- full_df[[i]] %>% 
      mutate(arm = "Control", 
             study_id = i)
  } else if (i > 10) {
    full_df[[i]] <- full_df[[i]] %>% 
      mutate(arm = "Experimental", 
             study_id = i - 10)
  }
}

full_df <- bind_rows(full_df) %>% 
  gather(key = week, value = obs, week_1:week_8) %>% 
  arrange(week, study_id) %>% 
  separate(col = week, into = c("delete", "week")) %>% 
  select(-delete)

```

Spagehtti plot:

``` {r}
full_df %>% 
  mutate(week = as.double(week), 
         study_id = as.character(study_id)) %>% 
  group_by(arm, study_id) %>% 
  ggplot(aes(x = week, y = obs, color = arm, type = study_id)) + 
    geom_line() + 
  theme_bw() + 
  labs(title = "Trends in observations across study period for each\n participant stratified by study arm",
       x = "Week", 
       y = "Observation") + 
  viridis::scale_color_viridis(name = "Study arm",
                               discrete = TRUE) 



```

Problem 3

```{r, warning=FALSE, message=FALSE}
# Define t-test function w/ set parameter
t_test <- function(mu = 0) {
  sample <- tibble(rnorm(n = 30, mean = mu, sd = 5))
  
  results <- t.test(sample) %>% 
    broom::tidy() %>% 
    select(estimate, p.value)
  
  results
}

# mean = 0
mean_0 <- expand_grid(mean = 0, 
                      iteration = 1:5000) %>% 
  mutate(results = map(mean, t_test)) %>% 
  unnest(results)

# mean = 1,2,3,4,5,6
mean_all <- expand_grid(mean = 1:6, 
                        iteration = 1:5000) %>% 
  mutate(results = map(mean, t_test)) %>% 
  unnest(results)
```


```{r, warning=FALSE, message=FALSE}
mean_all %>%
  group_by(mean) %>% 
  summarize(prop_rej = sum(p.value < 0.05)/5000) %>% 
  ggplot(aes(x = mean, y = prop_rej)) +
  scale_x_continuous(limits = c(1,6), breaks = seq(1,6,1)) + 
  geom_point() + 
  geom_path() 
```

When the true mean increases, the power increases. The rate of power increases tapers off as it approaches 1.

```{r, warning=FALSE, message=FALSE}
rejection <- mean_all %>% 
  filter(p.value < 0.05) %>% 
  group_by(mean) %>% 
  summarize(ave_est = mean(estimate, na.rm = T)) %>% 
  ungroup()

full_est <- mean_all %>% 
  group_by(mean) %>% 
  summarize(ave_est = mean(estimate, na.rm = T)) %>% 
  ungroup()
  
ggplot(full_est, aes(x = mean, y = ave_est)) +
  geom_line(data = full_est, aes(color = "purple")) +
  geom_line(data = rejection, aes(color = "red")) +
  scale_color_manual(name = " ", values = c("purple" = "purple", "red" = "red"),
                     labels = c('Rejected Estimates','All Estimates')) +
  geom_point(data = full_est, color = "purple") +
  geom_point(data = rejection, color = "red") +
  scale_x_continuous(limits = c(1,6), breaks = seq(1,6,1)) +
  labs(x = "True Mean", y = "Average Estimated Mean", title = "All and Rejected Mean Estimates")
```

For all estimates, the true mean is approximately equal to the average estimated mean. 
